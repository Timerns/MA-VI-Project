{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convert the data\n",
    "\n",
    "This notebook converts basic data from the CFF into processed data for use with Carto"
   ],
   "id": "903a94507a5d717b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-09T14:28:25.494373Z",
     "start_time": "2024-12-09T14:28:24.960244Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "df = pd.read_csv('../data/sbb-data.csv', delimiter=';')\n",
    "\n",
    "# split the Geopos column into two columns : latitude and longitude\n",
    "df[['latitude', 'longitude']] = df['Geopos'].str.split(',', expand=True)\n",
    "\n",
    "# convert the latitude and longitude columns to float\n",
    "df['latitude'] = df['latitude'].astype(float)\n",
    "df['longitude'] = df['longitude'].astype(float)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "429ab1b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:28:25.597481Z",
     "start_time": "2024-12-09T14:28:25.501385Z"
    }
   },
   "source": [
    "# convert the Departure time and Departure forecast columns to datetime\n",
    "df['Departure time'] = pd.to_datetime(df['Departure time'])\n",
    "df['Departure forecast'] = pd.to_datetime(df['Departure forecast'])\n",
    "df['Departure delay'] = df['Departure delay'].astype(bool)\n",
    "\n",
    "# add a column delay that contains the difference between the Departure forecast and the Departure time\n",
    "df['delay'] = df['Departure forecast']- df['Departure time']\n",
    "\n",
    "# replace all delay > 24h by NaT\n",
    "df.loc[df['delay'] > '24:00:00', 'delay'] = pd.NaT"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:28:26.237553Z",
     "start_time": "2024-12-09T14:28:26.183226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# group the data by Stop name and calculate various statistics\n",
    "station_data = df.groupby('Stop name').agg(\n",
    "    {'delay': 'max', 'Day of operation': 'count', 'Departure delay': 'sum'}).reset_index()\n",
    "station_data['delay rate'] = (station_data['Departure delay'] / station_data['Day of operation'] * 100).round(2)\n",
    "\n",
    "# take the unique values of Line Text for each station and concatenate them\n",
    "lines_per_station = df.groupby('Stop name')['Line Text'].unique().reset_index()\n",
    "lines_per_station['Line Text'] = lines_per_station['Line Text'].apply(lambda x: ', '.join(sorted(map(str, x))))\n",
    "\n",
    "# merge this information with station_data\n",
    "station_data = station_data.merge(lines_per_station[['Stop name', 'Line Text']], on='Stop name', how='left')\n",
    "\n",
    "# rename Line Text to All Lines\n",
    "station_data = station_data.rename(columns={'Line Text': 'All Lines'})"
   ],
   "id": "c8486b3fe306398b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:28:42.300216Z",
     "start_time": "2024-12-09T14:28:42.285050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# group the data by Line Text and calculate various statistics\n",
    "line_data = df.groupby('Line Text').agg({'Day of operation': 'count', 'Departure delay': 'sum'}).reset_index()\n",
    "line_data['delay rate'] = (line_data['Departure delay']/line_data['Day of operation'] * 100).round(2)"
   ],
   "id": "a2050ef0a5bc45df",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "4a06fe69f5ae7e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:28:44.156653Z",
     "start_time": "2024-12-09T14:28:42.723347Z"
    }
   },
   "source": [
    "# add the information to the initial data frame when the station name is the same and the line is the same\n",
    "data = df.merge(station_data, on='Stop name', how='left', suffixes=('', '_station'))\n",
    "data = data.merge(line_data, on='Line Text', how='left', suffixes=('', '_line'))\n",
    "\n",
    "# df['Departure delay'] transform boolean value to strings 'En retard' and 'Pas en retard'\n",
    "data['Departure delay'] = data['Departure delay'].replace({True: 'En retard', False: 'Pas en retard'})\n",
    "\n",
    "# replace 0 days by empty string\n",
    "data['delay_station'] = data['delay_station'].astype(str).str.replace('0 days ', '').replace('NaT', pd.NaT)\n",
    "\n",
    "# filter the data frame to keep only the relevant columns\n",
    "data = data[['Stop name', 'delay_station', 'Day of operation_station', 'Departure delay_station', 'All Lines', 'delay rate', 'longitude', 'latitude', 'Line Text', 'Day of operation_line', 'Departure delay_line', 'delay rate_line', 'Departure delay', 'Arrival forecast']]\n",
    "\n",
    "# rename column with better names\n",
    "data = data.set_axis(['nom gare', 'retard max gare', 'nombre total train gare', 'nombre retard train gare' , 'Toutes les lignes', 'taux retard gare', 'longitude', 'latitude', 'Nom Ligne', 'nombre total train ligne', 'nombre retard train ligne', 'taux retard ligne', 'retard', 'heure d\\'arriv√©'], axis=1)\n",
    "\n",
    "# save transformed data\n",
    "data.to_csv('../data/sbb-data_grouped.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
